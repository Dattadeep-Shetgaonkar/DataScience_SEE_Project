{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a3c147c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\virno\\anaconda3\\lib\\site-packages (0.49.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (4.66.5)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (24.1)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\virno\\anaconda3\\lib\\site-packages (from shap) (4.11.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from numba>=0.54->shap) (0.43.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\virno\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\virno\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bbd9e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\virno\\anaconda3\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e473081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9bd8412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ df reset. Shape: (54966, 15)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"healthcare_dataset_cleaned.csv\")\n",
    "\n",
    "# Convert dates again\n",
    "df[\"Date of Admission\"] = pd.to_datetime(df[\"Date of Admission\"], errors=\"coerce\")\n",
    "df[\"Discharge Date\"] = pd.to_datetime(df[\"Discharge Date\"], errors=\"coerce\")\n",
    "\n",
    "print(\"✅ df reset. Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa00612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== MODULE 2: FEATURE ENGINEERING =====\n",
      "\n",
      "✅ Length of Stay created successfully.\n",
      "\n",
      "Age: 0 outliers detected.\n",
      "Billing Amount: 0 outliers detected.\n",
      "Room Number: 0 outliers detected.\n",
      "Length of Stay: 0 outliers detected.\n",
      "\n",
      "✅ Outlier detection completed.\n",
      "\n",
      "Object columns found: ['Name', 'Gender', 'Blood Type', 'Medical Condition', 'Doctor', 'Hospital', 'Insurance Provider', 'Admission Type', 'Medication', 'Test Results']\n",
      "\n",
      "Label Encoded: ['Gender', 'Blood Type', 'Medical Condition', 'Insurance Provider', 'Admission Type', 'Medication', 'Test Results']\n",
      "Target Encoded: ['Name', 'Doctor', 'Hospital']\n",
      "\n",
      "✅ All categorical encoding completed successfully.\n",
      "\n",
      "✅ Final feature matrix prepared (numeric only).\n",
      "Final number of features: 15\n",
      "\n",
      "✅ Random Forest Feature Importance Computed.\n",
      "\n",
      "               Feature    Importance\n",
      "0                 Name  9.998423e-01\n",
      "7             Hospital  8.977689e-05\n",
      "6               Doctor  5.529903e-05\n",
      "12          Medication  2.100144e-06\n",
      "9          Room Number  2.038341e-06\n",
      "10      Admission Type  1.669826e-06\n",
      "8   Insurance Provider  1.450024e-06\n",
      "4    Medical Condition  1.110556e-06\n",
      "11      Discharge Date  9.061902e-07\n",
      "3           Blood Type  8.942063e-07\n",
      "5    Date of Admission  8.626098e-07\n",
      "14      Length of Stay  7.597729e-07\n",
      "1                  Age  7.259758e-07\n",
      "13        Test Results  7.712313e-08\n",
      "2               Gender  6.398413e-08\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# MODULE 2: FEATURE ENGINEERING + PREP\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"\\n===== MODULE 2: FEATURE ENGINEERING =====\\n\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1. FIX DATE COLUMNS & CREATE LENGTH OF STAY\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Convert to datetime\n",
    "date_cols = [\"Date of Admission\", \"Discharge Date\"]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Create Length of Stay\n",
    "df[\"Length of Stay\"] = (df[\"Discharge Date\"] - df[\"Date of Admission\"]).dt.days\n",
    "\n",
    "print(\"✅ Length of Stay created successfully.\\n\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2. OUTLIER DETECTION (IQR METHOD)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def detect_outliers_iqr(df, columns):\n",
    "    outlier_summary = {}\n",
    "    for col in columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        outliers = df[(df[col] < lower) | (df[col] > upper)].index\n",
    "        outlier_summary[col] = list(outliers)\n",
    "        print(f\"{col}: {len(outliers)} outliers detected.\")\n",
    "    return outlier_summary\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "outliers = detect_outliers_iqr(df, numeric_cols)\n",
    "\n",
    "print(\"\\n✅ Outlier detection completed.\\n\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3. HANDLE CATEGORICAL ENCODING (SMART + SAFE)\n",
    "# --------------------------------------------------\n",
    "\n",
    "object_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "print(\"Object columns found:\", object_cols)\n",
    "\n",
    "# Label Encode small-cardinality columns (<=10 unique)\n",
    "label_encode_cols = [col for col in object_cols if df[col].nunique() <= 10]\n",
    "\n",
    "# Target Encode high-cardinality columns (>10 unique)\n",
    "target_encode_cols = [col for col in object_cols if df[col].nunique() > 10]\n",
    "\n",
    "# ---- Label Encoding ----\n",
    "le = LabelEncoder()\n",
    "for col in label_encode_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "print(\"\\nLabel Encoded:\", label_encode_cols)\n",
    "\n",
    "# ---- Target Encoding ----\n",
    "for col in target_encode_cols:\n",
    "    means = df.groupby(col)[\"Billing Amount\"].mean()\n",
    "    df[col] = df[col].map(means)\n",
    "print(\"Target Encoded:\", target_encode_cols)\n",
    "\n",
    "print(\"\\n✅ All categorical encoding completed successfully.\\n\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4. PREPARE FINAL NUMERIC FEATURE MATRIX\n",
    "# --------------------------------------------------\n",
    "\n",
    "y = df[\"Billing Amount\"]\n",
    "\n",
    "# Drop target and any impossible features\n",
    "X = df.drop([\"Billing Amount\"], axis=1)\n",
    "\n",
    "# Convert DATETIME → numeric timestamps\n",
    "datetime_cols = X.select_dtypes(include=[\"datetime64[ns]\"]).columns\n",
    "for col in datetime_cols:\n",
    "    X[col] = X[col].astype(\"int64\") // 10**9\n",
    "\n",
    "# Ensure ALL features numeric\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "print(\"✅ Final feature matrix prepared (numeric only).\")\n",
    "print(f\"Final number of features: {X.shape[1]}\\n\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5. FEATURE SELECTION (Random Forest Importance)\n",
    "# --------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"✅ Random Forest Feature Importance Computed.\\n\")\n",
    "print(feature_importances.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90ea16a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBoost model trained successfully.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Train XGBoost\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"✅ XGBoost model trained successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52aa7b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 10995it [14:49, 12.28it/s]                           \n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "explainer = shap.Explainer(xgb.predict, X_train)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1caf398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab046dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train/Test Split Complete: (43972, 15) (10994, 15)\n",
      "\n",
      "===== Random Forest RESULTS =====\n",
      "MAE  : 4.4274813825604475\n",
      "MSE  : 9687.425326482347\n",
      "RMSE : 98.4247190825676\n",
      "R²   : 0.999952435370618\n",
      "\n",
      "===== Linear Regression RESULTS =====\n",
      "MAE  : 7.031575642347531\n",
      "MSE  : 3412.570703682682\n",
      "RMSE : 58.417212392262286\n",
      "R²   : 0.9999832444994113\n",
      "\n",
      "===== XGBoost RESULTS =====\n",
      "MAE  : 77.58980973322603\n",
      "MSE  : 18474.22646788042\n",
      "RMSE : 135.91992667699765\n",
      "R²   : 0.9999092927475102\n",
      "\n",
      "✅ Random Forest 5-Fold CV R²: 0.9997735766333353\n",
      "\n",
      "✅ Best RF Params: {'n_estimators': 300, 'min_samples_split': 10, 'max_depth': 10}\n",
      "\n",
      "===== BEST Random Forest RESULTS =====\n",
      "MAE  : 6.894335003988869\n",
      "MSE  : 9519.281914141184\n",
      "RMSE : 97.56680744054908\n",
      "R²   : 0.9999532609438555\n",
      "\n",
      "✅ Best XGB Params: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 400}\n",
      "\n",
      "===== BEST XGBoost RESULTS =====\n",
      "MAE  : 78.32148023143571\n",
      "MSE  : 17134.05768376543\n",
      "RMSE : 130.8971263388369\n",
      "R²   : 0.9999158728892277\n",
      "\n",
      "===== MODEL COMPARISON =====\n",
      "      Model        R²        RMSE\n",
      "0        RF  0.999952   98.424719\n",
      "1       XGB  0.999909  135.919927\n",
      "2        LR  0.999983   58.417212\n",
      "3   Best RF  0.999953   97.566807\n",
      "4  Best XGB  0.999916  130.897126\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================================================\n",
    "# FULL ADVANCED MACHINE LEARNING PIPELINE\n",
    "# ================================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. TRAIN–TEST SPLIT\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ Train/Test Split Complete:\", X_train.shape, X_test.shape)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# METRICS FUNCTION\n",
    "# ------------------------------------------------------------\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"\\n===== {name} RESULTS =====\")\n",
    "    print(f\"MAE  : {mae}\")\n",
    "    print(f\"MSE  : {mse}\")\n",
    "    print(f\"RMSE : {rmse}\")\n",
    "    print(f\"R²   : {r2}\")\n",
    "    return [mae, mse, rmse, r2]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. BASE MODELS (TRAIN + EVALUATE)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_metrics = evaluate_model(\"Random Forest\", y_test, rf_pred)\n",
    "\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_metrics = evaluate_model(\"Linear Regression\", y_test, lr_pred)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_metrics = evaluate_model(\"XGBoost\", y_test, xgb_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. CROSS-VALIDATION (K-Fold)\n",
    "# ------------------------------------------------------------\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "rf_cv_scores = []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    rf.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    preds = rf.predict(X.iloc[test_idx])\n",
    "    rf_cv_scores.append(r2_score(y.iloc[test_idx], preds))\n",
    "\n",
    "print(\"\\n✅ Random Forest 5-Fold CV R²:\", np.mean(rf_cv_scores))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. HYPERPARAMETER TUNING (GridSearch + RandomSearch)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# RANDOM FOREST RANDOM SEARCH\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 10, 20, None],\n",
    "    \"min_samples_split\": [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    rf, rf_params,\n",
    "    n_iter=10,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Best RF Params:\", rf_random.best_params_)\n",
    "\n",
    "best_rf = rf_random.best_estimator_\n",
    "best_rf_pred = best_rf.predict(X_test)\n",
    "evaluate_model(\"BEST Random Forest\", y_test, best_rf_pred)\n",
    "\n",
    "\n",
    "# XGBOOST GRID SEARCH\n",
    "xgb_params = {\n",
    "    \"max_depth\": [4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"n_estimators\": [200, 400],\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb, xgb_params,\n",
    "    scoring=\"r2\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "print(\"\\n✅ Best XGB Params:\", xgb_grid.best_params_)\n",
    "\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "best_xgb_pred = best_xgb.predict(X_test)\n",
    "evaluate_model(\"BEST XGBoost\", y_test, best_xgb_pred)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. MODEL COMPARISON DASHBOARD\n",
    "# ------------------------------------------------------------\n",
    "model_scores = pd.DataFrame({\n",
    "    \"Model\": [\"RF\", \"XGB\", \"LR\", \"Best RF\", \"Best XGB\"],\n",
    "    \"R²\": [rf_metrics[3], xgb_metrics[3], lr_metrics[3],\n",
    "           r2_score(y_test, best_rf_pred), r2_score(y_test, best_xgb_pred)],\n",
    "    \"RMSE\": [rf_metrics[2], xgb_metrics[2], lr_metrics[2],\n",
    "             np.sqrt(mean_squared_error(y_test, best_rf_pred)),\n",
    "             np.sqrt(mean_squared_error(y_test, best_xgb_pred))]\n",
    "})\n",
    "\n",
    "print(\"\\n===== MODEL COMPARISON =====\")\n",
    "print(model_scores)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=model_scores, x=\"Model\", y=\"R²\")\n",
    "plt.title(\"Model R² Comparison\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b22501c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost==1.7.6 in c:\\users\\virno\\anaconda3\\lib\\site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from xgboost==1.7.6) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\virno\\anaconda3\\lib\\site-packages (from xgboost==1.7.6) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost==1.7.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4badb02d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[2.5558773E4]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Create SHAP explainer using your trained XGBoost model\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mTreeExplainer(xgb)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Compute SHAP values for the test set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n",
      "File \u001b[1;32mc:\\Users\\virno\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:278\u001b[0m, in \u001b[0;36mTreeExplainer.__init__\u001b[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, link, linearize_link)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_perturbation \u001b[38;5;241m=\u001b[39m feature_perturbation\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m TreeEnsemble(model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_missing, model_output)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# check for unsupported combinations of feature_perturbation and model_outputs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\virno\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:1279\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[1;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m safe_isinstance(model, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost.sklearn.XGBRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost.sklearn.XGBRanker\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[1;32m-> 1279\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_xgboost_model_attributes(\n\u001b[0;32m   1280\u001b[0m         data,\n\u001b[0;32m   1281\u001b[0m         data_missing,\n\u001b[0;32m   1282\u001b[0m         objective_name_map,\n\u001b[0;32m   1283\u001b[0m         tree_output_name_map,\n\u001b[0;32m   1284\u001b[0m     )\n\u001b[0;32m   1285\u001b[0m     \u001b[38;5;66;03m# Some properties of the sklearn API are passed to a DMatrix object in\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;66;03m# xgboost We need to make sure we do the same here - GH #3313\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_xgb_dmatrix_props \u001b[38;5;241m=\u001b[39m get_xgboost_dmatrix_properties(model)\n",
      "File \u001b[1;32mc:\\Users\\virno\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:1506\u001b[0m, in \u001b[0;36mTreeEnsemble._set_xgboost_model_attributes\u001b[1;34m(self, data, data_missing, objective_name_map, tree_output_name_map)\u001b[0m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_xgboost_model_attributes\u001b[39m(\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1500\u001b[0m     data,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     tree_output_name_map,\n\u001b[0;32m   1504\u001b[0m ):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1506\u001b[0m     loader \u001b[38;5;241m=\u001b[39m XGBTreeModelLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_model)\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mget_trees(data\u001b[38;5;241m=\u001b[39mdata, data_missing\u001b[38;5;241m=\u001b[39mdata_missing)\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_offset \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mbase_score\n",
      "File \u001b[1;32mc:\\Users\\virno\\anaconda3\\Lib\\site-packages\\shap\\explainers\\_tree.py:2104\u001b[0m, in \u001b[0;36mXGBTreeModelLoader.__init__\u001b[1;34m(self, xgb_model)\u001b[0m\n\u001b[0;32m   2102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(diff[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   2103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;241m=\u001b[39m n_targets\n\u001b[1;32m-> 2104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(learner_model_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_obj \u001b[38;5;241m=\u001b[39m objective[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '[2.5558773E4]'"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 7. SHAP EXPLAINABILITY (for XGB)\n",
    "# ------------------------------------------------------------\n",
    "import shap\n",
    "\n",
    "# Create SHAP explainer using your trained XGBoost model\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary Plot\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ All models saved successfully!\n",
      "✅ Loaded RF Model: RandomForestRegressor(max_depth=10, min_samples_split=10, n_estimators=300,\n",
      "                      n_jobs=-1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 8. SAVE MODELS\n",
    "# ------------------------------------------------------------\n",
    "pickle.dump(best_rf, open(\"best_random_forest.pkl\", \"wb\"))\n",
    "pickle.dump(best_xgb, open(\"best_xgboost.pkl\", \"wb\"))\n",
    "pickle.dump(lr, open(\"linear_regression.pkl\", \"wb\"))\n",
    "\n",
    "print(\"\\n✅ All models saved successfully!\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 9. LOAD MODELS (example)\n",
    "# ------------------------------------------------------------\n",
    "loaded_rf = pickle.load(open(\"best_random_forest.pkl\", \"rb\"))\n",
    "print(\"✅ Loaded RF Model:\", loaded_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
